{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import json\n",
    "import io\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(n = 0.7):\n",
    "    time1 = time.time()\n",
    "    # import files\n",
    "    review_json_file = '/Users/mjy/Downloads/yelp_dataset/review.json'\n",
    "\n",
    "    review = []\n",
    "    for line in open(review_json_file, 'r'):\n",
    "        review.append(json.loads(line))\n",
    "\n",
    "    # convert to dataframe\n",
    "    review_df = pd.DataFrame.from_records(review)\n",
    "    # extract the userful column\n",
    "    review_df = review_df.loc[:,['business_id','user_id','stars','text']]\n",
    "    # split the test and training dataset\n",
    "    length = int(len(review_df) * n)\n",
    "\n",
    "    review_df_training = review_df.iloc[:length,]\n",
    "    review_df_test = review_df.iloc[length:,]\n",
    "    review_df_training.to_csv('training_large.csv')\n",
    "    #review_df_test.to_csv('test.csv')\n",
    "    time2 = time.time()\n",
    "    print('SUCCESS!!!  train_test_split')\n",
    "    print('The training set has ', length, 'rows data')\n",
    "    print('The testing set has ', len(review_df) - length, 'rows data')\n",
    "    print('Time: ', time2 - time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textProcessing(text):\n",
    "    # lower words  \n",
    "    text = text.lower()\n",
    "    # remove punctuation\n",
    "    for c in string.punctuation:\n",
    "        text = text.replace(c, ' ')\n",
    "    # tokenize\n",
    "    wordLst = nltk.word_tokenize(text)\n",
    "    # stop word\n",
    "    filtered = [w for w in wordLst if w not in stopwords.words('english')]\n",
    "    # keep noun  \n",
    "    refiltered =nltk.pos_tag(filtered)\n",
    "    filtered = [w for w, pos in refiltered if pos.startswith('NN')]\n",
    "    # xtract the stem\n",
    "    ps = PorterStemmer()\n",
    "    filtered = [ps.stem(w) for w in filtered]\n",
    "\n",
    "    return \" \".join(filtered) \n",
    "\n",
    "def rating_proportion(text,rate):\n",
    "    return text * int(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lda(review,n_topic = 10,n_top_words=20):\n",
    "# vectorization\n",
    "# generate the word-docu matrix\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,stop_words='english')\n",
    "    tf = tf_vectorizer.fit_transform(review)\n",
    "# train the lda model\n",
    "    lda = LatentDirichletAllocation(n_topics=n_topic, \n",
    "                                max_iter=50,\n",
    "                                learning_method='batch')\n",
    "    lda.fit(tf)\n",
    "# print the performance\n",
    "    print('perplexity is: ',lda.perplexity(tf))\n",
    "\n",
    "# generate the top word list for every topic\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    feature_dict = {k: v for v, k in enumerate(tf_feature_names)}\n",
    "\n",
    "    for topic_idx, topic in enumerate(lda.components_):       \n",
    "        print (\"Topic #%d:\" % topic_idx)\n",
    "        print (\" \".join([tf_feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))    \n",
    "\n",
    "# return the topic*word distribution matrix\n",
    "    return lda.components_,feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topic_probability(document,feature_dict,topic_word_matrix):\n",
    "    word_list = document.split()\n",
    "    topic_num = len(topic_word_matrix)\n",
    "    topic_probability = {k:0 for k in range(topic_num)}\n",
    "    for topic_idx in range(topic_num):\n",
    "        for word in word_list:\n",
    "            if word in feature_dict.keys():\n",
    "                topic_probability[topic_idx] += topic_word_matrix[topic_idx,feature_dict[word]]\n",
    "    return topic_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def normalize(x):\n",
    "    normalized_list = []\n",
    "    new_dict = {}\n",
    "    for key,value in x.items():\n",
    "        normalized_list.append(value**2)\n",
    "    for key,value in x.items():\n",
    "        if sum(normalized_list) == 0:\n",
    "            new_dict[key] = 0\n",
    "        else:\n",
    "            new_dict[key] = value/math.sqrt(sum(normalized_list))\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS!!!  train_test_split\n",
      "The training set has  53487 rows data\n",
      "The testing set has  6632413 rows data\n",
      "Time:  604.2358219623566\n"
     ]
    }
   ],
   "source": [
    "train_test_split(n = 0.008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training_large.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b1b1eb3uo-w561D0ZfCEiQ</td>\n",
       "      <td>ssoyf2_x0EQMed6fgHeMyQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             business_id                 user_id  stars  \\\n",
       "0           0  ujmEBvifdJM6h6RLv4wQIg  hG7b0MtEbXx5QzbzE6C_VA    1.0   \n",
       "1           1  NZnhc2sEQy3RmzKTZnqtwQ  yXQM5uF2jS6es16SJzNHfg    5.0   \n",
       "2           2  WTqjgwHlXbSFevF32_DJVw  n6-Gk65cPZL6Uz8qRm3NYw    5.0   \n",
       "3           3  ikCg8xy5JIg_NGPx-MSIDA  dacAIZ6fTM6mqwW5uxkskg    5.0   \n",
       "4           4  b1b1eb3uo-w561D0ZfCEiQ  ssoyf2_x0EQMed6fgHeMyQ    1.0   \n",
       "\n",
       "                                                text  \n",
       "0  Total bill for this horrible service? Over $8G...  \n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...  \n",
       "2  I have to say that this office really has it t...  \n",
       "3  Went in for a lunch. Steak sandwich was delici...  \n",
       "4  Today was my second out of three sessions I ha...  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate user_id, biz_id dict\n",
    "user_raw_int_id_dic = {v: k for k,v in enumerate(training['user_id'].unique())}\n",
    "biz_raw_int_id_dic = {v: k for k,v in enumerate(training['business_id'].unique())}\n",
    "\n",
    "#transform str_id to int_id and keep them in the dataframe\n",
    "training['user_int_id'] = training['user_id'].apply(lambda x: user_raw_int_id_dic[x])\n",
    "training['biz_int_id'] = training['business_id'].apply(lambda x: biz_raw_int_id_dic[x])\n",
    "\n",
    "#Generate Rating Sparse Matrix\n",
    "user_row = training['user_int_id'].values\n",
    "biz_column = training['biz_int_id'].values\n",
    "\n",
    "user_num = len(user_raw_int_id_dic)\n",
    "biz_num = len(biz_raw_int_id_dic)\n",
    "\n",
    "rating_data = training['stars'].values\n",
    "rating_matrix = sparse.csr_matrix((rating_data, (user_row, biz_column)), shape=(user_num, biz_num))\n",
    "#c.todense()\n",
    "#c.toarray()\n",
    "\n",
    "training['text'] = training['text'].apply(textProcessing)\n",
    "training['text'] = training['text'] * training['stars'].apply(int)\n",
    "\n",
    "review_by_user = training.groupby('user_int_id').text.sum()\n",
    "review_by_business = training.groupby('biz_int_id').text.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#review_by_user.to_csv('review_by_user.csv')\n",
    "#review_by_business.to_csv('review_by_business.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjy/Desktop/Anaconda3/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity is:  1008.7512013664086\n",
      "Topic #0:\n",
      "night bar drink glass bartend cocktail nail hour club le water la date tabl bottl loung patio girl shot vibe\n",
      "Topic #1:\n",
      "chicken dish roll sauc soup rice salad beef restaur sushi spici meat flavor meal shrimp steak place pork potato menu\n",
      "Topic #2:\n",
      "coffe breakfast cream ice egg tea chocol flavor cake place dessert bacon cooki day sandwich tast fruit brunch cup waffl\n",
      "Topic #3:\n",
      "food servic place time restaur order price staff menu server dinner peopl experi star tabl wait minut meal portion everyth\n",
      "Topic #4:\n",
      "time vega peopl dog fun place music game friend seat year la parti event line everyon group way thing son\n",
      "Topic #5:\n",
      "time servic custom work car day job care staff thank year experi compani busi guy home phone price minut offic\n",
      "Topic #6:\n",
      "room hotel time hair area place staff park pool class floor day machin cut locat peopl year bathroom lot way\n",
      "Topic #7:\n",
      "pizza beer select place wine time spot sandwich wing salad bread order list crust deliveri pasta home hous owner slice\n",
      "Topic #8:\n",
      "burger fri chicken taco food chip place sauc order bean meat bbq burrito pork sandwich onion flavor time rice corn\n",
      "Topic #9:\n",
      "store price kid place shop buffet select item staff massag product lot qualiti stuff daughter section time locat thing dress\n"
     ]
    }
   ],
   "source": [
    "review = training['text'] \n",
    "topic_word_matrix,feature_dict = lda(review,n_topic=10,n_top_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_by_user = pd.DataFrame(training.groupby('user_int_id').text.sum())  #index: user_int_id, column='text'\n",
    "review_by_business = pd.DataFrame(training.groupby('biz_int_id').text.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_int_id\n",
       "0        {0: 1061.014864514111, 1: 1855.3580856209928, ...\n",
       "1        {0: 13912.773006129635, 1: 85917.59344165497, ...\n",
       "2        {0: 458.6097052269172, 1: 14655.200141416446, ...\n",
       "3        {0: 61430.6674076248, 1: 59274.265743235286, 2...\n",
       "4        {0: 5545.214049928087, 1: 30826.34591631713, 2...\n",
       "5        {0: 27345.40806521046, 1: 298601.3050848628, 2...\n",
       "6        {0: 93177.03328936029, 1: 350267.69062919164, ...\n",
       "7        {0: 5983.918967256919, 1: 61635.27744214379, 2...\n",
       "8        {0: 27936.012458051984, 1: 52257.9848778678, 2...\n",
       "9        {0: 367.2193425254425, 1: 1142.4274750745064, ...\n",
       "10       {0: 13508.134267592694, 1: 156536.6653177368, ...\n",
       "11       {0: 34496.919664962414, 1: 6678.497880623954, ...\n",
       "12       {0: 7819.17205801262, 1: 270713.28985019145, 2...\n",
       "13       {0: 8281.467892442768, 1: 32000.696645465665, ...\n",
       "14       {0: 3987.897094887616, 1: 50910.77555150958, 2...\n",
       "15       {0: 7729.692785638037, 1: 111714.55557177155, ...\n",
       "16       {0: 576.002058264633, 1: 84680.49244078125, 2:...\n",
       "17       {0: 79459.43752248943, 1: 1074622.2339367212, ...\n",
       "18       {0: 3665.9027046516712, 1: 64450.097693214564,...\n",
       "19       {0: 119332.01275422279, 1: 177517.14051443397,...\n",
       "20       {0: 2.10042433395618, 1: 13896.151990610886, 2...\n",
       "21       {0: 19256.66807889952, 1: 230252.644078453, 2:...\n",
       "22       {0: 73389.44211013794, 1: 79608.36281655116, 2...\n",
       "23       {0: 615.7239868167417, 1: 96854.62026944806, 2...\n",
       "24       {0: 9490.086866416344, 1: 148858.8699711967, 2...\n",
       "25       {0: 10952.265696306018, 1: 28627.23285696179, ...\n",
       "26       {0: 4180.255299200289, 1: 21890.760854625692, ...\n",
       "27       {0: 898.7636512132524, 1: 22609.736252502607, ...\n",
       "28       {0: 3630.5106961549013, 1: 43427.72911314855, ...\n",
       "29       {0: 11355.265946261945, 1: 48738.00322254752, ...\n",
       "                               ...                        \n",
       "45740    {0: 187.689854524357, 1: 12804.003304825432, 2...\n",
       "45741    {0: 2147.6368837547484, 1: 13871.253705784948,...\n",
       "45742    {0: 1902.6237771255169, 1: 6122.991766308637, ...\n",
       "45743    {0: 1971.1897016239445, 1: 32992.32868882525, ...\n",
       "45744    {0: 2149.8804602379464, 1: 37371.29961112436, ...\n",
       "45745    {0: 25679.163299077307, 1: 214960.39314266996,...\n",
       "45746    {0: 6607.064420173777, 1: 69275.5882548779, 2:...\n",
       "45747    {0: 3839.996066049637, 1: 46173.28473073723, 2...\n",
       "45748    {0: 917.2084020529543, 1: 78300.71374746707, 2...\n",
       "45749    {0: 21368.92677524282, 1: 27899.819152230466, ...\n",
       "45750    {0: 9654.45389730617, 1: 38534.57977972927, 2:...\n",
       "45751    {0: 6932.410898243194, 1: 93810.88189185131, 2...\n",
       "45752    {0: 183559.84318158147, 1: 67211.2945456169, 2...\n",
       "45753    {0: 986.507631250559, 1: 207008.23923057306, 2...\n",
       "45754    {0: 182879.81535331777, 1: 238163.0687567717, ...\n",
       "45755    {0: 65.4601921962238, 1: 17.799514194676004, 2...\n",
       "45756    {0: 668.8793500609332, 1: 22839.671789817923, ...\n",
       "45757    {0: 3332.414196122434, 1: 28951.832717133766, ...\n",
       "45758    {0: 544.3692306460058, 1: 91255.81295436493, 2...\n",
       "45759    {0: 2.1003854493137806, 1: 1711.6863440526165,...\n",
       "45760    {0: 671.1276993622506, 1: 58591.917630872296, ...\n",
       "45761    {0: 21450.66458106106, 1: 84221.61234799537, 2...\n",
       "45762    {0: 3625.4821205673425, 1: 84696.9618598268, 2...\n",
       "45763    {0: 124209.02841649685, 1: 207460.67143908737,...\n",
       "45764    {0: 5744.634251948578, 1: 259925.98771424696, ...\n",
       "45765    {0: 5443.0220154653025, 1: 146351.03413926746,...\n",
       "45766    {0: 14148.654125033956, 1: 22950.404449312286,...\n",
       "45767    {0: 11353.255395300095, 1: 75556.02336876746, ...\n",
       "45768    {0: 3858.8927999117245, 1: 33474.056244547835,...\n",
       "45769    {0: 124.35573040119941, 1: 20215.79515973896, ...\n",
       "Name: text, Length: 45770, dtype: object"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_by_user['text'].apply(lambda x: topic_probability(x,feature_dict,topic_word_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_by_user['topic_pro_list'] = (review_by_user['text'].\n",
    "                                    apply(lambda x: topic_probability(x,feature_dict,topic_word_matrix)).\n",
    "                                    apply(normalize))\n",
    "review_by_business['topic_pro_list'] = (review_by_business['text'].\n",
    "                                        apply(lambda x: topic_probability(x,feature_dict,topic_word_matrix)).\n",
    "                                        apply(normalize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7752796240788413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjy/Desktop/Anaconda3/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n",
      "/Users/mjy/Desktop/Anaconda3/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in multiply\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#calculate the KL between two variables\n",
    "def KL(a, b):\n",
    "    a = np.asarray(a, dtype=np.float)\n",
    "    b = np.asarray(b, dtype=np.float)\n",
    "    return np.sum(np.where(a != 0, a * np.log(a / b), 0))\n",
    "\n",
    "values1 = [1.346112,1.337432,1.246655, 0]\n",
    "values2 = [1.033836,1.082015,1.117323, 0.01]\n",
    "\n",
    "print(KL(values1, values2))\n",
    "\n",
    "#calculate the KL similarity between two variables\n",
    "def KL_sim(a,b):\n",
    "    a = np.array(list(map(lambda x: 1e-4 if x==0 else x, a)))\n",
    "    a = np.asarray(a, dtype=np.float)\n",
    "    b = np.array(list(map(lambda x: 1e-4 if x==0 else x, b)))\n",
    "    b = np.asarray(b, dtype=np.float)\n",
    "    KL_ab = np.sum(np.where(a != 0, a * np.log(a/b), 0))\n",
    "    KL_ba = np.sum(np.where(b != 0, b * np.log(b/a),0))\n",
    "    return np.exp(-(KL_ab+KL_ba)/2)\n",
    "\n",
    "KL_sim(values1, values2) #0.9274102245965972   1e-4\n",
    "#0.002983985448228528    1e-4\n",
    "#0.0007321799208767189   1e-5\n",
    "#0.00017971959287665066  1e-6\n",
    "#4.4115655560183375e-05  1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KL Similarity Function          <font color='red'>TODO: Parameters tuning - Is replacing 0 with 1e-4 the best choice?</font>\n",
    "\n",
    "Why replace 0 with a small number:  np.log(a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9065084978369279"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.stats.entropy(values1,values2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5065062664852481"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def KL_sim(a,b):\n",
    "    KL_ab = scipy.stats.entropy(a,b)\n",
    "    KL_ba = scipy.stats.entropy(b,a)\n",
    "    return np.exp(-(KL_ab+KL_ba)/2)\n",
    "\n",
    "KL_sim(values1, values2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create the businessID_listID dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get User-Topic/Business-Topic Numpy Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45770, 10)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_num = len(review_by_user['topic_pro_list'])\n",
    "user_topic = np.zeros([user_num, 10])\n",
    "for i in range(user_num):\n",
    "    for j in range(0,10):\n",
    "        user_topic[i][j] = review_by_user['topic_pro_list'][i][j] # row: user; column: topic\n",
    "        \n",
    "user_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_num = len(review_by_business['topic_pro_list'])\n",
    "business_topic =  np.zeros([business_num, 10])\n",
    "for i in range(business_num):\n",
    "    for j in range(0,10):\n",
    "        business_topic[i][j]=review_by_business['topic_pro_list'][i][j]  #row; business_id; column:topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10968, 10)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_topic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate User-Business Probability Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_business_pro = np.dot(user_topic,business_topic.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45770, 10968)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_business_pro.shape # row : user, column = business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import correlation, cosine\n",
    "\n",
    "def findksimilarusers(user_id, ratings, metric = 'cosine', k=1):\n",
    "    similarities=[]\n",
    "    indices=[]\n",
    "    model_knn = NearestNeighbors(metric = metric, algorithm = 'brute') \n",
    "    model_knn.fit(ratings)\n",
    "\n",
    "    distances, indices = model_knn.kneighbors(ratings.iloc[user_id-1, :].values.reshape(1, -1), n_neighbors = k+1)\n",
    "    similarities = 1-distances.flatten()\n",
    "    print('{0} most similar users for User {1}:\\n'.format(k,user_id))\n",
    "    for i in range(0, len(indices.flatten())):\n",
    "        if indices.flatten()[i]+1 == user_id:\n",
    "            continue;\n",
    "\n",
    "        else:\n",
    "            print('{0}: User {1}, with similarity of {2}'.format(i, indices.flatten()[i]+1, similarities.flatten()[i]))\n",
    "            \n",
    "    return similarities,indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 most similar users for User 1:\n",
      "\n",
      "1: User 22361, with similarity of 0.9999969791877369\n",
      "2: User 11374, with similarity of 0.9999964037324052\n",
      "3: User 43616, with similarity of 0.9999962657738\n",
      "4: User 15375, with similarity of 0.9999961354682665\n",
      "5: User 13922, with similarity of 0.9999961131844802\n",
      "time used: -114.18974685668945\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "similarities,indices = findksimilarusers(1, pd.DataFrame(user_business_pro), metric='cosine', k =5)\n",
    "end = time.time()\n",
    "print('time used:', start - end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function predicts rating for specified user-item combination based on user-based approach\n",
    "def predict_userbased(user_id, item_id, ratings, metric = 'cosine', k=5):\n",
    "    prediction=0\n",
    "    similarities, indices=findksimilarusers(user_id, ratings,metric, k) #similar users based on cosine similarity\n",
    "    mean_rating = ratings.loc[user_id-1,:].mean() #to adjust for zero based indexing\n",
    "    sum_wt = np.sum(similarities)-1\n",
    "    product=1\n",
    "    wtd_sum = 0 \n",
    "    \n",
    "    for i in range(0, len(indices.flatten())):\n",
    "        if indices.flatten()[i]+1 == user_id:\n",
    "            continue;\n",
    "        else: \n",
    "            ratings_diff = ratings.iloc[indices.flatten()[i],item_id-1]-np.mean(ratings.iloc[indices.flatten()[i],:])\n",
    "            product = ratings_diff * (similarities[i])\n",
    "            wtd_sum = wtd_sum + product\n",
    "    \n",
    "    prediction = int(round(mean_rating + (wtd_sum/sum_wt)))\n",
    "    print('\\nPredicted rating for user {0} -> item {1}: {2}'.format(user_id,item_id,prediction))\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 most similar users for User 3:\n",
      "\n",
      "1: User 30313, with similarity of 0.9999542862521746\n",
      "2: User 12527, with similarity of 0.9999519626136075\n",
      "3: User 4158, with similarity of 0.9999449538228273\n",
      "4: User 43316, with similarity of 0.9999257201648606\n",
      "5: User 23083, with similarity of 0.999923507290708\n",
      "\n",
      "Predicted rating for user 3 -> item 4: 0\n",
      "time used: -87.60992002487183\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "predict_userbased(3,4,pd.DataFrame(user_business_pro));\n",
    "end = time.time()\n",
    "print('time used:', start - end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate User-User Similarity and Business-Business Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-11a8c0672469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0muser_similarity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0muser_similarity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKL_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_business_pro\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_business_pro\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-103-8f1da0fbe68f>\u001b[0m in \u001b[0;36mKL_sim\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#calculate the KL similarity between two variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mKL_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1e-4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1e-4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-8f1da0fbe68f>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#calculate the KL similarity between two variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mKL_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1e-4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1e-4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "user_similarity = np.zeros([user_num, user_num])\n",
    "for i in range(user_num):\n",
    "    for j in range(user_num):\n",
    "        if i== j:\n",
    "            user_similarity[i][j] = 1\n",
    "        else:\n",
    "            user_similarity[i][j] = KL_sim(user_business_pro[i],user_business_pro[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_similarity = np.zeros([business_num,business_num])\n",
    "for i in range(business_num):\n",
    "    for j in range(business_num):\n",
    "        if i==j:\n",
    "            business_similarity[i][j] = 1\n",
    "        else: \n",
    "            business_similarity[i][j] = KL_sim(user_business_pro[:,i], user_business_pro[:,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-User recommender   \n",
    "#### <font color='red'>TODO: Parameters tuning - how many top similar users should be chosen? K = 10 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([423, 347, 502, 134,  25, 251, 413, 235, 149, 186, 313, 515, 554,\n",
       "       227, 260])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_k_similar_user(user_id = None,k= 15, biz_id = None):\n",
    "    #get the similar user_id who have rated the item\n",
    "    user_rated_item_id = [id_ for id_ in range(num_user) if rating_matrix[id_,biz_id]!=0]\n",
    "    #find the most similar user\n",
    "    if len(user_rated_item_id)< k:\n",
    "        return 'not enough similar users'\n",
    "    else:\n",
    "        #[1,4,6,7]\n",
    "        index_list = np.argsort(user_similarity[user_id])[-k-1:-1]\n",
    "#    user_ID_list = [user_ID_dic[i] for i in index_list]\n",
    "    return index_list\n",
    "\n",
    "top_similar_user_list = get_top_k_similar_user(user_id=0,k = 15)\n",
    "top_similar_user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_k_similar_user(user_id = None,k= 15, biz_id = None):\n",
    "    #get the similar user_id who have rated the item\n",
    "    user_rated_item_id = [id_ for id_ in range(num_user) if rating_matrix[id_,biz_id]!=0]\n",
    "    #find the most similar user\n",
    "    if len(user_rated_item_id)< k:\n",
    "        return 'not enough similar users'\n",
    "    else:\n",
    "        index_list = (pd.DataFrame(user_similarity[user_id]).\n",
    "                      loc[user_rated_item_id].\n",
    "                      sort_values(by = 0, ascending = False)[1:k+1].index)\n",
    "        return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_k_similar_user(user_id = 10, k= 15, biz_id = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# user dictionary (raw ID) - (assigned int ID)\n",
    "user_raw_int_dic = {value:key for key, value in user_ID_dic.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_mean_rating_dic = training.groupby('user_id').stars.mean().to_dict()\n",
    "user_mean_rating_dic = {user_raw_int_dic[key]:_ for key, _ in user_mean_rating_dic.items()}\n",
    "# user_mean_rating_dic {int_ID: mean_rating}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mean_rating_dic = training.groupby('user_int_id').stars.mean().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>TODO: Creating a user_biz rating matrix (with int ID) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>user_int_id</th>\n",
       "      <th>biz_int_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bill servic crook pill pill cent hospit er cost</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>rock salon stranger chain servic flawless leve...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>offic j phillipp dentist dental assist procedu...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>steak sandwich caesar salad amount leaf drink ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b1b1eb3uo-w561D0ZfCEiQ</td>\n",
       "      <td>ssoyf2_x0EQMed6fgHeMyQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>today session session enjoy male client fine r...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             business_id                 user_id  stars  \\\n",
       "0           0  ujmEBvifdJM6h6RLv4wQIg  hG7b0MtEbXx5QzbzE6C_VA    1.0   \n",
       "1           1  NZnhc2sEQy3RmzKTZnqtwQ  yXQM5uF2jS6es16SJzNHfg    5.0   \n",
       "2           2  WTqjgwHlXbSFevF32_DJVw  n6-Gk65cPZL6Uz8qRm3NYw    5.0   \n",
       "3           3  ikCg8xy5JIg_NGPx-MSIDA  dacAIZ6fTM6mqwW5uxkskg    5.0   \n",
       "4           4  b1b1eb3uo-w561D0ZfCEiQ  ssoyf2_x0EQMed6fgHeMyQ    1.0   \n",
       "\n",
       "                                                text  user_int_id  biz_int_id  \n",
       "0    bill servic crook pill pill cent hospit er cost            0           0  \n",
       "1  rock salon stranger chain servic flawless leve...            1           1  \n",
       "2  offic j phillipp dentist dental assist procedu...            2           2  \n",
       "3  steak sandwich caesar salad amount leaf drink ...            3           3  \n",
       "4  today session session enjoy male client fine r...            4           4  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0]\n",
      " [ 0  3  0  0  0]\n",
      " [ 0  0  0 15  0]\n",
      " [ 0  0  3  0  2]\n",
      " [ 0  0  0  0  0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "import numpy as np\n",
    " \n",
    "row = [1,2, 3, 3, 2]\n",
    "col = [1,3, 4, 2, 3]\n",
    "data = [3,5, 2, 3, 10]\n",
    "c = sparse.csr_matrix((data, (row, col)), shape=(5, 5))\n",
    "\n",
    "print(c.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Rating Sparse Matrix\n",
    "user_row = training['user_int_id'].values\n",
    "biz_column = training['biz_int_id'].values\n",
    "\n",
    "user_num = len(user_raw_int_id_dic)\n",
    "biz_num = len(biz_raw_int_id_dic)\n",
    "\n",
    "rating_data = training['stars'].values\n",
    "rating_matrix = sparse.csr_matrix((rating_data, (user_row, biz_column)), shape=(user_num, biz_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5283383351520485"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rating_prediction(user_id = 1, biz_id = 10, top_k = 15):\n",
    "    user_i_mean_rating = user_mean_rating_dic[user_id]\n",
    "    top_similar_user_list = get_top_k_similar_user(user_id ,k = top_k)\n",
    "    #list to store user info: mean rating, rating given biz_id, similarity\n",
    "    u_info = []\n",
    "   \n",
    "    for similar_user in top_similar_user_list:\n",
    "        mean_rating = user_mean_rating_dic[similar_user]        \n",
    "        rating_u_i = rating_matrix[similar_user, biz_id]\n",
    "        similarity = user_similarity[user_id][similar_user]\n",
    "        u_info.append([mean_rating, rating_u_i, similarity])\n",
    "    \n",
    "    similar_user_rating = np.sum([(u_info[i][1] - u_info[i][0])*u_info[i][2] for i in range(top_k)])\n",
    "    sum_of_similarity = np.sum([u_info[i][2] for i in range(top_k)])\n",
    "    predicted_rating = user_i_mean_rating+ similar_user_rating/sum_of_similarity\n",
    "    return predicted_rating\n",
    "    \n",
    "rating_prediction(user_id = 5, biz_id = 2, top_k = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.8834872202102697,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5954787175746898,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.725473742408274,\n",
       " 0.5283383351520485,\n",
       " 0.595948925714203,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.8455041844667002,\n",
       " 0.5283383351520485,\n",
       " 0.5944138862293311,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.8000325325077351,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.8834872202102697,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.7380466551117566,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.7237615342999764,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.8454547624909976,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.7190050309537441,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485,\n",
       " 0.5283383351520485]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rating_prediction_list = []\n",
    "for i in range(300):\n",
    "    user_rating_prediction_list.append(rating_prediction(user_id = 5, biz_id = i, top_k = 15))\n",
    "user_rating_prediction_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business-Business Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. first get the top 10 users\n",
    "\n",
    "def get_top_k_similar_business(user_id,k):\n",
    "    #get the index of most similar user\n",
    "    index_list = np.argsort(business_similarity[1])[-k-1:-1]\n",
    "    biz_ID_list = [user_ID_dic[i] for i in index_list]\n",
    "    return biz_ID_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
